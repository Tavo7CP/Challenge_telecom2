# Challenge_telecom2
¬°Listo! Te dejo una versi√≥n **corregida, estructurada y m√°s profesional** de tu texto, lista para usar como `README.md`:

---

# üìâ TelecomX ‚Äî Predicci√≥n de Cancelaci√≥n de Clientes (Churn)

Proyecto de **an√°lisis y modelado predictivo** para anticipar la cancelaci√≥n de clientes en una empresa de telecomunicaciones. Combina **EDA**, **machine learning** y **herramientas de interpretabilidad** (SHAP) para comprender los factores que influyen en el abandono y proponer **estrategias de retenci√≥n** efectivas.

## üìÅ Estructura del repositorio

```
TelecomX-Churn
‚îú‚îÄ‚îÄ data/                       # Datos procesados y tratados
‚îú‚îÄ‚îÄ notebooks/                  # Notebooks de an√°lisis y modelado
‚îú‚îÄ‚îÄ models/                     # Modelos entrenados (opcional)
‚îú‚îÄ‚îÄ outputs/                    # Resultados y visualizaciones
‚îú‚îÄ‚îÄ informe_cancelacion_telecom_x.md   # Informe t√©cnico en Markdown
‚îú‚îÄ‚îÄ requirements.txt            # Paquetes necesarios
‚îî‚îÄ‚îÄ README.md                   # Este archivo
```

## üß† Objetivo del proyecto

Desarrollar un modelo que **prediga la cancelaci√≥n** de un cliente a partir de sus **caracter√≠sticas de contrato**, **historial de pagos** y **uso de servicios**, habilitando acciones proactivas para **reducir la tasa de churn**.

## üß™ Proceso de desarrollo

**1) Carga y limpieza de datos**

* Eliminaci√≥n de identificadores √∫nicos (ID).
* Codificaci√≥n de variables categ√≥ricas con `get_dummies`.
* Balanceo de clases con **SMOTE**.
* Normalizaci√≥n con **StandardScaler**.

**2) An√°lisis exploratorio (EDA)**

* Histogramas, boxplots y matriz de correlaci√≥n.
* Identificaci√≥n de variables influyentes.
* An√°lisis de churn por **tipo de contrato**, **servicios** y **m√©todo de pago**.

**3) Selecci√≥n de caracter√≠sticas**

* `SelectKBest` con `f_classif`.
* **K √≥ptimo: 29** variables por rendimiento.

**4) Entrenamiento de modelos**

* **Regresi√≥n Log√≠stica** (`LogisticRegression`)
* **Random Forest** (`RandomForestClassifier`)
* **Gradient Boosting** (`GradientBoostingClassifier`)
* **K-Nearest Neighbors** (KNN)
* **Ensemble** (VotingClassifier: **LR + GB**)

**5) Optimizaci√≥n de hiperpar√°metros**

* **GridSearchCV** con validaci√≥n cruzada estratificada.

**6) Evaluaci√≥n**

* M√©tricas: **Accuracy, Precision, Recall, F1 Score**.
* **Matriz de confusi√≥n**.
* **Curva ROC** y **AUC**.
* Interpretabilidad con **SHAP** y coeficientes log√≠sticos.

## üèÜ Resultados

| Modelo                 |  Accuracy  |  Precision | Recall | F1 Score |    AUC    |
| ---------------------- | :--------: | :--------: | :----: | :------: | :-------: |
| Gradient Boosting      |   0.7887   |   0.5907   | 0.5864 |  0.5886  |   0.850   |
| Regresi√≥n Log√≠stica    |   0.7956   |   0.5997   | 0.6221 |  0.6107  |   0.840   |
| **Ensemble (LR + GB)** | **0.8025** | **0.6277** | 0.5740 |  0.5996  | **0.851** |

‚úÖ El **Ensemble (LR + GB)** combina la **interpretabilidad** de LR y el **desempe√±o** de GB, logrando el **mejor AUC**.

## üîç Principales factores de cancelaci√≥n

(Seg√∫n **SHAP** y correlaci√≥n)

* Contratos **‚Äúmonth-to-month‚Äù**.
* M√©todo de pago: **electronic check**.
* **Ausencia** de servicios adicionales (soporte t√©cnico, seguridad, respaldo online).
* **Baja antig√ºedad** (pocos meses en la empresa).
* **Altos cargos mensuales** y **bajo engagement**.

## üí° Estrategias de retenci√≥n sugeridas

* Incentivar **contratos de mayor plazo** (1‚Äì2 a√±os).
* Ofrecer **bundles** de valor (soporte + seguridad + respaldo).
* Promover **pagos autom√°ticos** (tarjeta o transferencia).
* **Monitoreo proactivo** a clientes con cargos mensuales altos.
* **Programas de fidelizaci√≥n** para clientes nuevos o con baja antig√ºedad.

## ‚öôÔ∏è Requisitos

* Python **3.8+**
* `pandas`, `numpy`, `matplotlib`, `seaborn`
* `scikit-learn`, `imblearn`, `shap`

Instalaci√≥n r√°pida:

```bash
pip install -r requirements.txt
```

> Si no usas `requirements.txt`, instala manualmente:
>
> ```bash
> pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn shap
> ```

## ‚ñ∂Ô∏è C√≥mo reproducir

1. Clona el repositorio y crea un entorno virtual.
2. Instala dependencias (`pip install -r requirements.txt`).
3. Abre los notebooks en `notebooks/` y ejecuta en orden:

   * `01_eda.ipynb` ‚Üí EDA y preprocesamiento
   * `02_feature_selection.ipynb` ‚Üí Selecci√≥n de variables
   * `03_modeling.ipynb` ‚Üí Entrenamiento, tuning y evaluaci√≥n
   * `04_explainability.ipynb` ‚Üí SHAP y an√°lisis interpretativo
4. Revisa resultados en `outputs/` y modelos (si se guardan) en `models/`.

---
  Autor: Gustavo Angel Chaparro Pacheco
